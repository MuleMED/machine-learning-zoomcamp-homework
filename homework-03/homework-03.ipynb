{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4824e44e-2a27-46b4-babe-d1d135bb9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b111cea-055d-4647-ad22-5c8cf6d56ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1462, 9)\n",
      "\n",
      "First few rows:\n",
      "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
      "0      paid_ads         NaN                         1        79450.0   \n",
      "1  social_media      retail                         1        46992.0   \n",
      "2        events  healthcare                         5        78796.0   \n",
      "3      paid_ads      retail                         2        83843.0   \n",
      "4      referral   education                         3        85012.0   \n",
      "\n",
      "  employment_status       location  interaction_count  lead_score  converted  \n",
      "0        unemployed  south_america                  4        0.94          1  \n",
      "1          employed  south_america                  1        0.80          0  \n",
      "2        unemployed      australia                  3        0.69          1  \n",
      "3               NaN      australia                  1        0.87          0  \n",
      "4     self_employed         europe                  3        0.62          1  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "path = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aaed254-bf35-4b8f-9a11-7639c5fbf47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after handling:\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation - Handle missing values\n",
    "cat_cols = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "num_cols = ['annual_income']\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna('NA')\n",
    "\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(0.0)\n",
    "\n",
    "print(\"Missing values after handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23d82dc-0f58-4912-8c4b-7a4058ab4a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry value counts:\n",
      "industry\n",
      "retail        203\n",
      "finance       200\n",
      "other         198\n",
      "healthcare    187\n",
      "education     187\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Question 1 Answer: Most frequent industry is 'retail'\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Most frequent observation for industry\n",
    "industry_mode = df['industry'].mode()[0]\n",
    "industry_counts = df['industry'].value_counts()\n",
    "print(\"Industry value counts:\")\n",
    "print(industry_counts.head())\n",
    "print(f\"\\nQuestion 1 Answer: Most frequent industry is '{industry_mode}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82006b9c-4f54-48e6-99d5-82f10484b56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "\n",
      "                          interaction_count  lead_score  \n",
      "number_of_courses_viewed          -0.023565   -0.004879  \n",
      "annual_income                      0.027036    0.015610  \n",
      "interaction_count                  1.000000    0.009888  \n",
      "lead_score                         0.009888    1.000000  \n",
      "\n",
      "Top correlated pairs:\n",
      "annual_income & interaction_count: 0.0270\n",
      "number_of_courses_viewed & interaction_count: 0.0236\n",
      "annual_income & lead_score: 0.0156\n",
      "\n",
      "Specific pairs from question:\n",
      "interaction_count & lead_score: 0.0099\n",
      "number_of_courses_viewed & lead_score: 0.0049\n",
      "number_of_courses_viewed & interaction_count: 0.0236\n",
      "annual_income & interaction_count: 0.0270\n",
      "\n",
      "Question 2 Answer: annual_income and interaction_count\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Correlation matrix for numerical features\n",
    "numerical_features = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Find the pair with highest absolute correlation (excluding diagonal)\n",
    "corr_pairs = []\n",
    "for i in range(len(numerical_features)):\n",
    "    for j in range(i+1, len(numerical_features)):\n",
    "        feat1, feat2 = numerical_features[i], numerical_features[j]\n",
    "        corr_val = correlation_matrix.loc[feat1, feat2]\n",
    "        corr_pairs.append(((feat1, feat2), abs(corr_val)))\n",
    "\n",
    "# Sort by absolute correlation\n",
    "corr_pairs_sorted = sorted(corr_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop correlated pairs:\")\n",
    "for (feat1, feat2), corr_val in corr_pairs_sorted[:3]:\n",
    "    print(f\"{feat1} & {feat2}: {corr_val:.4f}\")\n",
    "\n",
    "# Check the specific pairs mentioned in the question\n",
    "print(\"\\nSpecific pairs from question:\")\n",
    "pairs_to_check = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'), \n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "max_corr = 0\n",
    "max_pair = None\n",
    "for feat1, feat2 in pairs_to_check:\n",
    "    corr_val = abs(correlation_matrix.loc[feat1, feat2])\n",
    "    print(f\"{feat1} & {feat2}: {corr_val:.4f}\")\n",
    "    if corr_val > max_corr:\n",
    "        max_corr = corr_val\n",
    "        max_pair = (feat1, feat2)\n",
    "\n",
    "print(f\"\\nQuestion 2 Answer: {max_pair[0]} and {max_pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a746dc2-3aae-4453-9c4b-a5bfa86cbd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 877 samples\n",
      "Val set: 292 samples\n",
      "Test set: 293 samples\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X = df.drop('converted', axis=1)\n",
    "y = df['converted']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"Val set: {X_val.shape[0]} samples\") \n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e964c7-0dd3-420c-9fb3-ac7413357da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores:\n",
      "industry: 0.02\n",
      "location: 0.0\n",
      "lead_source: 0.03\n",
      "employment_status: 0.02\n",
      "\n",
      "Question 3 Answer: lead_source\n"
     ]
    }
   ],
   "source": [
    "# Question 3: Mutual information with categorical variables\n",
    "categorical_features = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "\n",
    "mi_scores = {}\n",
    "for feature in categorical_features:\n",
    "    mi = mutual_info_score(y_train, X_train[feature])\n",
    "    mi_scores[feature] = round(mi, 2)\n",
    "\n",
    "print(\"Mutual Information Scores:\")\n",
    "for feature, score in mi_scores.items():\n",
    "    print(f\"{feature}: {score}\")\n",
    "\n",
    "max_mi_feature = max(mi_scores, key=mi_scores.get)\n",
    "print(f\"\\nQuestion 3 Answer: {max_mi_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f62a27-ae5f-4e45-9dee-0663d2074942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded train features: (877, 31)\n",
      "Encoded val features: (292, 31)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for logistic regression (one-hot encoding)\n",
    "# Combine train and val for encoding to avoid dimension mismatch\n",
    "X_combined = pd.concat([X_train, X_val])\n",
    "y_combined = pd.concat([y_train, y_val])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_features = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "X_encoded = pd.get_dummies(X_combined, columns=categorical_features, prefix=categorical_features)\n",
    "\n",
    "# Split back into train and val\n",
    "X_train_encoded = X_encoded.iloc[:len(X_train)]\n",
    "X_val_encoded = X_encoded.iloc[len(X_train):len(X_train)+len(X_val)]\n",
    "\n",
    "print(f\"Encoded train features: {X_train_encoded.shape}\")\n",
    "print(f\"Encoded val features: {X_val_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733d56cf-1a8a-43cc-8879-1adc2b710f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7432\n",
      "Rounded to 2 decimals: 0.74\n",
      "\n",
      "Question 4 Answer: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_val_pred = model.predict(X_val_encoded)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "accuracy_rounded = round(accuracy, 2)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Rounded to 2 decimals: {accuracy_rounded}\")\n",
    "\n",
    "print(f\"\\nQuestion 4 Answer: {accuracy_rounded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "438b930a-2ccc-4cef-84fc-f2220fae1a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: 0.7432\n",
      "Without industry: accuracy = 0.7432, difference = 0.0000\n",
      "Without employment_status: accuracy = 0.7466, difference = -0.0034\n",
      "Without lead_score: accuracy = 0.7432, difference = 0.0000\n",
      "\n",
      "Question 5 Answer: industry\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Feature elimination\n",
    "original_accuracy = accuracy_score(y_val, model.predict(X_val_encoded))\n",
    "print(f\"Original accuracy: {original_accuracy:.4f}\")\n",
    "\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "accuracy_differences = {}\n",
    "\n",
    "for feature in features_to_test:\n",
    "    if feature == 'lead_score':  # numerical feature\n",
    "        features_to_drop = [feature]\n",
    "    else:  # categorical feature - drop all its one-hot encoded columns\n",
    "        features_to_drop = [col for col in X_train_encoded.columns if col.startswith(feature + '_')]\n",
    "    \n",
    "    X_train_reduced = X_train_encoded.drop(columns=features_to_drop)\n",
    "    X_val_reduced = X_val_encoded.drop(columns=features_to_drop)\n",
    "    \n",
    "    model_reduced = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_reduced.fit(X_train_reduced, y_train)\n",
    "    \n",
    "    reduced_accuracy = accuracy_score(y_val, model_reduced.predict(X_val_reduced))\n",
    "    difference = original_accuracy - reduced_accuracy\n",
    "    \n",
    "    accuracy_differences[feature] = difference\n",
    "    print(f\"Without {feature}: accuracy = {reduced_accuracy:.4f}, difference = {difference:.4f}\")\n",
    "\n",
    "min_diff_feature = min(accuracy_differences, key=lambda x: abs(accuracy_differences[x]))\n",
    "print(f\"\\nQuestion 5 Answer: {min_diff_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68566f80-65c1-4d6d-83f7-cd4bdfedc702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression Results:\n",
      "C = 0.01: Accuracy = 0.7432 (Rounded: 0.743)\n",
      "C = 0.1: Accuracy = 0.7432 (Rounded: 0.743)\n",
      "C = 1: Accuracy = 0.7432 (Rounded: 0.743)\n",
      "C = 10: Accuracy = 0.7432 (Rounded: 0.743)\n",
      "C = 100: Accuracy = 0.7432 (Rounded: 0.743)\n",
      "\n",
      "Question 6 Answer: C = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Question 6: Regularized Logistic Regression\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "best_accuracy = 0\n",
    "best_C = None\n",
    "\n",
    "print(\"Regularized Logistic Regression Results:\")\n",
    "for C in C_values:\n",
    "    model_reg = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model_reg.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    y_val_pred_reg = model_reg.predict(X_val_encoded)\n",
    "    accuracy_reg = accuracy_score(y_val, y_val_pred_reg)\n",
    "    accuracy_rounded_3 = round(accuracy_reg, 3)\n",
    "    \n",
    "    print(f\"C = {C}: Accuracy = {accuracy_reg:.4f} (Rounded: {accuracy_rounded_3})\")\n",
    "    \n",
    "    if accuracy_reg > best_accuracy:\n",
    "        best_accuracy = accuracy_reg\n",
    "        best_C = C\n",
    "\n",
    "print(f\"\\nQuestion 6 Answer: C = {best_C}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
